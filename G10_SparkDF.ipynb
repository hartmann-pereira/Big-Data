{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python SparkDF\n",
    "The final output gives the number of monitors for each U.S.A. state using the FIPS code with also includes islands and self governing territories.\n",
    "\n",
    "This notebook exemplifies the execution of a pySpark program in Python, using the SQL interface. In this example, spark runs in standalone mode and reads data from the local filesystem, while in cluster mode data is read typically from HDFS dsitributed file system.\n",
    "\n",
    "Spark documentation available at: https://spark.apache.org/docs/2.3.1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset \n",
    "Dataset is being downloaded from a dropbox link Contains a small subset of the original dataset Dataset contains the information from air quality monitoring facilities across the U.S.A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-21 18:12:16--  https://www.dropbox.com/s/4jxfdsgn2tdo7zo/epa_hap_daily_summary-small.csv?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.68.18, 2620:100:6024:18::a27d:4412\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.68.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/4jxfdsgn2tdo7zo/epa_hap_daily_summary-small.csv [following]\n",
      "--2021-12-21 18:12:22--  https://www.dropbox.com/s/raw/4jxfdsgn2tdo7zo/epa_hap_daily_summary-small.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucb9f10291b576dc53170c4903a7.dl.dropboxusercontent.com/cd/0/inline/BcT71uf70pqC1K8qG3mlYuZjyfFyGMG1bkiF9qaKguPZ6HZhFnC7ba3rJuqjveGvpIyht6IuaqtzEmQFb_UTYdkhcgUGnyZ2tggJjJFSpY6zoJuHAFjgiq7Q3obMKBmWSJ0eK5BMS0EBiQc4CdXrlE9A/file# [following]\n",
      "--2021-12-21 18:12:23--  https://ucb9f10291b576dc53170c4903a7.dl.dropboxusercontent.com/cd/0/inline/BcT71uf70pqC1K8qG3mlYuZjyfFyGMG1bkiF9qaKguPZ6HZhFnC7ba3rJuqjveGvpIyht6IuaqtzEmQFb_UTYdkhcgUGnyZ2tggJjJFSpY6zoJuHAFjgiq7Q3obMKBmWSJ0eK5BMS0EBiQc4CdXrlE9A/file\n",
      "Resolving ucb9f10291b576dc53170c4903a7.dl.dropboxusercontent.com (ucb9f10291b576dc53170c4903a7.dl.dropboxusercontent.com)... 162.125.68.15, 2620:100:6024:15::a27d:440f\n",
      "Connecting to ucb9f10291b576dc53170c4903a7.dl.dropboxusercontent.com (ucb9f10291b576dc53170c4903a7.dl.dropboxusercontent.com)|162.125.68.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 123020165 (117M) [text/plain]\n",
      "Saving to: ‘epa_hap_daily_summary_small’\n",
      "\n",
      "epa_hap_daily_summa 100%[===================>] 117.32M  2.34MB/s    in 88s     \n",
      "\n",
      "2021-12-21 18:13:53 (1.33 MB/s) - ‘epa_hap_daily_summary_small’ saved [123020165/123020165]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O epa_hap_daily_summary_small https://www.dropbox.com/s/4jxfdsgn2tdo7zo/epa_hap_daily_summary-small.csv?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('Q1').getOrCreate()\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile('epa_hap_daily_summary_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.option(\"header\",\"true\").csv(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, state_code: string, county_code: string, site_num: string, parameter_code: string, poc: string, latitude: string, longitude: string, datum: string, parameter_name: string, sample_duration: string, pollutant_standard: string, date_local: string, units_of_measure: string, event_type: string, observation_count: string, observation_percent: string, arithmetic_mean: string, first_max_value: string, first_max_hour: string, aqi: string, method_code: string, method_name: string, local_site_name: string, address: string, state_name: string, county_name: string, city_name: string, cbsa_name: string, date_of_last_change: string]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_values = df = spark.read.csv(lines,inferSchema =True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_values_small = monitor_values.drop('parameter_code','county_name','arithmetic_mean','county_code','site_num','poc','latitude','longitude','datum','parameter_name','sample_duration','pollutant_standard','date_local','units_of_measure','event_type','observation_count','observation_percent','first_max_value','first_max_hour','aqi','method_code','method_name','local_site_name','state_name','city_name','cbsa_name','date_of_last_change')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|state_code|             address|\n",
      "+----------+--------------------+\n",
      "|        34|Interchange 13 Ne...|\n",
      "|        35|     San Pedro Parks|\n",
      "|        51|2401 HARTMAN STRE...|\n",
      "|        48|  1902 WEST SCHUNIOR|\n",
      "|        44|FRANCIS SCHOOL 64...|\n",
      "|        36|POST OFFICE350 CA...|\n",
      "|        36|274 S Pearl St Al...|\n",
      "|        39|         1330 DUEBER|\n",
      "|        48|800 S San Marcial...|\n",
      "|        16|            Scoville|\n",
      "+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monitor_values_small.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns_duplicRows = monitor_values_small.dropDuplicates(['address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|state_code|             address|\n",
      "+----------+--------------------+\n",
      "|        35|          San Andres|\n",
      "|         6|5551 BETHEL ISLAN...|\n",
      "|        41|        711 WELCH ST|\n",
      "|        20|FIRE STA.#8; SHUN...|\n",
      "|        54|1400 Main St / 10...|\n",
      "|        22|U.S. Coast Guard ...|\n",
      "|        72|FIRE DEPARTMENTCR...|\n",
      "|        22|HEALTH UNIT BUILD...|\n",
      "|        12|7200-22 AVENUE NORTH|\n",
      "|        27|    649 FIFTH STREET|\n",
      "+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_columns_duplicRows.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have now cleaned all my data and now only need to count the state code instances and show a table in descending order\n",
    "I need to group by state code column and use a counting function, after that I apply a sort and specify that I want column count to be ordered descending, a final show is applied to present the final result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|state_code|count|\n",
      "+----------+-----+\n",
      "|         6|  161|\n",
      "|        48|  132|\n",
      "|        27|   94|\n",
      "|        39|   89|\n",
      "|        26|   83|\n",
      "|        36|   66|\n",
      "|        45|   64|\n",
      "|        30|   60|\n",
      "|        42|   60|\n",
      "|        12|   57|\n",
      "|        18|   52|\n",
      "|         8|   50|\n",
      "|        17|   49|\n",
      "|        37|   49|\n",
      "|        53|   42|\n",
      "|        22|   40|\n",
      "|         4|   38|\n",
      "|        20|   37|\n",
      "|        13|   34|\n",
      "|        41|   31|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_columns_duplicRows.groupBy('state_code').count().sort(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
